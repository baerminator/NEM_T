{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing, time, torch, os, scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from relax import RELAX\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "from medclip.dataset import constants\n",
    "from masking_network import medclip_masking_net\n",
    "from medclip import  MedCLIPVisionModel, constants\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lung_data(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        \n",
    "        img    = Image.open(row[\"img_path\"])\n",
    "        img = img.convert(\"RGB\")\n",
    "        \n",
    "        \n",
    "        return self.transform(img) , row[\"img_path\"]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = \"data/RSNA_DATASET/\"\n",
    "df = pd.read_csv('data/RSNA_DATASET/stage_2_train_labels.csv')\n",
    "df = df.drop_duplicates(subset=['patientId',\"Target\"], keep='first')\n",
    "df[\"img_path\"] = df.Target.apply(lambda x: \"PNEUMONIA\" if x == 1 else \"NORMAL\")\n",
    "df[\"img_path\"] = df.apply(lambda row: data_path +row[\"img_path\"] + \"/\" + str(row['patientId']) + \".png\", axis=1)\n",
    "df = df[['img_path', 'Target',\"x\",\"y\",\"width\",\"height\"]]\n",
    "df.columns = ['img_path', 'target',\"x\",\"y\",\"width\",\"height\"]\n",
    "\n",
    "df = df.fillna(0)\n",
    "df[\"x\"] = (df[\"x\"]/1024 * 224).astype(int)\n",
    "df[\"y\"] = (df[\"y\"]/1024 * 224).astype(int)\n",
    "df[\"width\"] = (df[\"width\"]/1024 * 224).astype(int)\n",
    "df[\"height\"] = (df[\"height\"]/1024 * 224).astype(int)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only take test data with bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRANS =  transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        transforms.Normalize(\n",
    "            mean=constants.IMG_MEAN,\n",
    "            std=constants.IMG_STD,),  # Normalize using precomputed mean and std\n",
    "        transforms.Resize((224, 224),antialias=True),\n",
    "    ])\n",
    "only_bounding_box =  test_df[test_df.target==1]\n",
    "only_bounding_box = only_bounding_box.sample(1000,replace=False,random_state=42)\n",
    "only_bounding_box\n",
    "data_set_train = lung_data(train_df, transform=TRANS)\n",
    "data_set_test = lung_data(only_bounding_box, transform=TRANS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "## TODO AUTO DOWNLOAD THE VISION MODEL weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MedCLIPVisionModel().to(\"cuda\")\n",
    "model.load_from_medclip(\"./pretrained/medclip-resnet\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEM-U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH = 32\n",
    "NUM_WORKERS = multiprocessing.cpu_count() - 2\n",
    "EPOCHS = 10\n",
    "MIXED_PRECISION = False\n",
    "DETERMINISTIC = False\n",
    "CONTRASTIVE = True\n",
    "NOISE_MASK = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = medclip_masking_net(EPOCHS,BATCH,constrastive=CONTRASTIVE,noise_mask=NOISE_MASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_set_train, batch_size=BATCH, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_set_test, batch_size=BATCH, shuffle=False)\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS,\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "        precision=16 if MIXED_PRECISION else 32,\n",
    "        default_root_dir=\"masking_unsupervised_pneumonia_logs\",\n",
    "        accumulate_grad_batches=int(128/BATCH,),\n",
    "        deterministic=DETERMINISTIC\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "nem_path = \"result/unsupervised/pneunomia/nem/\"\n",
    "os.makedirs(nem_path,exist_ok=True)\n",
    "execution_times = []\n",
    "for (img, name) in data_set_test:\n",
    "    name = name.split(\"/\")[-1]\n",
    "    img = img.unsqueeze(0).to(\"cuda\")\n",
    "    start_time = time.time()\n",
    "    attr, _  = model(img)\n",
    "    execution_times.append(time.time()-start_time)\n",
    "    x = img.squeeze().permute(1,2,0).cpu().detach().numpy()\n",
    "    x = ((x - x.min()) / (x.max() - x.min()))*255\n",
    "    attr = attr.cpu().squeeze().detach().numpy()\n",
    "    attr = (((attr - attr.min()) / (attr.max() - attr.min()))*255).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    Image.fromarray(attr).save(f\"{nem_path}{name}\")\n",
    "\n",
    "print(\"Average execution time: \", np.array(execution_times).sum()/len(execution_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MedCLIPVisionModel().to(\"cuda\")\n",
    "model.load_from_medclip(\"pretrained/medclip-resnet\")\n",
    "model.eval()\n",
    "relax_path = \"result/unsupervised/pneunomia/relax/\"\n",
    "U_relax_path  = \"result/unsupervised/pneunomia/u_relax/\"\n",
    "execution_times = []\n",
    "for (img, name) in data_set_test:\n",
    "    name = name.split(\"/\")[-1]\n",
    "    relax = RELAX(img.unsqueeze(0).cuda(),model)\n",
    "    start_time = time.time()\n",
    "    relax()\n",
    "    execution_times.append(time.time()-start_time)\n",
    "    x = img.permute(1,2,0).cpu().detach().numpy()\n",
    "    x = ((x - x.min()) / (x.max() - x.min()))*255\n",
    "    attr = relax.importance().cpu().squeeze().detach().numpy()\n",
    "    attr = (((attr - attr.min()) / (attr.max() - attr.min()))*255).astype(np.uint8)\n",
    "    uncertainty = (relax.U_RELAX().cpu().squeeze().detach().numpy())\n",
    "    uncertainty = ((uncertainty - uncertainty.min()) / (uncertainty.max()- uncertainty.min())*255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    Image.fromarray(attr).save(f\"{relax_path}{name}\")\n",
    "    Image.fromarray(uncertainty).save(f\"{U_relax_path}{name}\")\n",
    "print(\"Average execution time: \", np.array(execution_times).sum()/len(execution_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_bounding_box(x,y,w,h, size=(224,224)):\n",
    "    \"generate a boundingbox mask using numpy and the input coordinates\"\n",
    "    mask = np.zeros(size)\n",
    "    mask[y:y+h, x:x+w] = 1\n",
    "    return mask.astype(np.uint8)\n",
    "mask_path = \"result/masks/pneunomia/\"\n",
    "os.makedirs(mask_path, exist_ok=True)\n",
    "for sample in only_bounding_box.iterrows():\n",
    "   mask =  gen_bounding_box(sample[1][\"x\"],sample[1][\"y\"],sample[1][\"width\"],sample[1][\"height\"])\n",
    "   Image.fromarray(mask).save(f\"{mask_path}{sample[1]['img_path'].split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Experimental method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(metrics, metric_names):\n",
    "    data= only_bounding_box\n",
    "    res_path = \"result/unsupervised/pneunomia/\"\n",
    "    mask_path = \"result/masks/pneunomia/\"\n",
    "    MEDCLIP_relax_path = f\"{res_path}relax/\"\n",
    "    MEDCLIP_u_relax_path = f\"{res_path}u_relax/\"\n",
    "    MEDCLIP_nem_path = f\"{res_path}nem/\"\n",
    "\n",
    "    for metric_func,metric_name in zip(metrics,metric_names):\n",
    "        MEDCLIP_relax_res = metric_func(mask_path=mask_path, explanation_path=MEDCLIP_relax_path, samples=data)\n",
    "        MEDCLIP_u_relax_res = metric_func(mask_path=mask_path, explanation_path=MEDCLIP_u_relax_path, samples=data)\n",
    "        MEDCLIP_nem_res = metric_func(mask_path=mask_path, explanation_path=MEDCLIP_nem_path, samples=data)\n",
    "\n",
    "        print(f\"\"\"\n",
    "        {metric_name}:\n",
    "        MEDCLIP_relax:     {MEDCLIP_relax_res}\n",
    "        MEDCLIP_U_relax:   {MEDCLIP_u_relax_res}\n",
    "        MEDCLIP_NEM:       {MEDCLIP_nem_res}\n",
    "        \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_rank( mask_path, explanation_path, samples, uncertainty=False):\n",
    "    rank_accuracy = 0\n",
    "    samps = 0\n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        s = (np.array(Image.open(mask_path + img_name)) > 0).astype(np.uint8)\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # Prepare shapes.\n",
    "        a = a.flatten()\n",
    "        s = np.where(s.flatten().astype(bool))[0]\n",
    "        # Size of the ground truth mask.\n",
    "        k = len(s)\n",
    "        # Sort in descending order.\n",
    "        a_sorted = np.argsort(a)[-int(k) :]\n",
    "        # Calculate hits.\n",
    "        hits = len(np.intersect1d(s, a_sorted))\n",
    "        if hits != 0:\n",
    "            rank_accuracy += hits / float(k)\n",
    "        else:\n",
    "            rank_accuracy += 0.0\n",
    "        samps +=1 \n",
    "\n",
    "\n",
    "\n",
    "    return rank_accuracy/ samps\n",
    "\n",
    "def relevancy_mass(mask_path, explanation_path, samples, uncertainty=False):\n",
    "    mass_accuracy_total = 0\n",
    "    samps = 0\n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        s = (np.array(Image.open(mask_path + img_name)) > 0).astype(np.uint8)\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # \n",
    "        a = a.flatten()\n",
    "        s = s.flatten().astype(bool)\n",
    "        # Compute inside/outside ratio.\n",
    "        r_within = np.sum(a[s])\n",
    "        r_total = np.sum(a)\n",
    "        # Calculate mass accuracy.\n",
    "        mass_accuracy = r_within / r_total\n",
    "        mass_accuracy_total += mass_accuracy\n",
    "        samps +=1\n",
    "\n",
    "    return mass_accuracy_total/ samps\n",
    "     \n",
    "\n",
    "run_exp([\n",
    "     relevance_rank, relevancy_mass],\n",
    "        [\n",
    " \"Relevance Rank\", \"Relevancy Mass\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complexity( mask_path, explanation_path, samples,uncertainty=False):\n",
    "    complexity = 0\n",
    "    \n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # Prepare shapes.\n",
    "        newshape = np.prod(a.shape)\n",
    "        a = np.array(np.reshape(a, newshape), dtype=np.float64) / np.sum(np.abs(a))\n",
    "        complexity += scipy.stats.entropy(pk=a)   \n",
    "\n",
    "\n",
    "    return complexity/ len(samples)\n",
    "\n",
    "\n",
    "def sparseness( mask_path, explanation_path, samples,uncertainty=False):\n",
    "    complexity = 0\n",
    "    \n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # Prepare shapes.\n",
    "        newshape = np.prod(a.shape)\n",
    "        a = np.array(np.reshape(a, newshape), dtype=np.float64)\n",
    "        a += 0.0000001\n",
    "        a = np.sort(a)\n",
    "        complexity += (np.sum((2 * np.arange(1, a.shape[0] + 1) - a.shape[0] - 1) * a)) / (\n",
    "            a.shape[0] * np.sum(a)\n",
    "        )\n",
    "\n",
    "    return complexity/ len(samples)\n",
    "\n",
    "\n",
    "run_exp([\n",
    "    complexity, \n",
    "    sparseness\n",
    "    ],\n",
    "        [\n",
    "    \"Complexity\", \n",
    "    \"Sparseness\"\n",
    "    ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MICCAI_COMPARE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
