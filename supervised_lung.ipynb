{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, warnings, torch, multiprocessing, skimage, scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from timm import create_model\n",
    "from prodigyopt import Prodigy\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms\n",
    "from model_extractors import resnet50_img_extractor\n",
    "from masking_network import resnet50_trained_extractor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import IntegratedGradients\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from torchray.attribution.extremal_perturbation import extremal_perturbation, contrastive_reward\n",
    "from quantus.metrics.faithfulness.faithfulness_estimate import FaithfulnessEstimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lung_data(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform=None, grayscale=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = 2\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        if self.grayscale:\n",
    "           img = skimage.io.imread(row[\"img_path\"])\n",
    "           img = np.expand_dims(img, axis=0)\n",
    "           img = self.transform(img)\n",
    "           return torch.from_numpy(img), np.eye(self.num_classes)[row[\"target\"]]\n",
    "        \n",
    "        img    = Image.open(row[\"img_path\"])\n",
    "        img = img.convert(\"RGB\")\n",
    "         \n",
    "        img = self.transform (img) if self.transform !=None else img \n",
    "        return img, np.eye(self.num_classes)[row[\"target\"]],  row[\"img_path\"]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = \"data/RSNA_DATASET/\"\n",
    "df = pd.read_csv('data/RSNA_DATASET/stage_2_train_labels.csv')\n",
    "df = df.drop_duplicates(subset=['patientId',\"Target\"], keep='first')\n",
    "df[\"img_path\"] = df.Target.apply(lambda x: \"PNEUMONIA\" if x == 1 else \"NORMAL\")\n",
    "df[\"img_path\"] = df.apply(lambda row: data_path +row[\"img_path\"] + \"/\" + str(row['patientId']) + \".png\", axis=1)\n",
    "df = df[['img_path', 'Target',\"x\",\"y\",\"width\",\"height\"]]\n",
    "df.columns = ['img_path', 'target',\"x\",\"y\",\"width\",\"height\"]\n",
    "\n",
    "df = df.fillna(0)\n",
    "df[\"x\"] = (df[\"x\"]/1024 * 224).astype(int)\n",
    "df[\"y\"] = (df[\"y\"]/1024 * 224).astype(int)\n",
    "df[\"width\"] = (df[\"width\"]/1024 * 224).astype(int)\n",
    "df[\"height\"] = (df[\"height\"]/1024 * 224).astype(int)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRANS  =  transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],),  # Normalize using precomputed mean and std\n",
    "        transforms.Resize((224, 224),antialias=True),\n",
    "    ])\n",
    "\n",
    "data_set_model_train = lung_data(train_df, transform=TRANS)\n",
    "data_set_model_test = lung_data(test_df, transform=TRANS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2253244, 0.7746756])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights =  len(train_df)/np.array(train_df.target.value_counts())\n",
    "weights = weights/np.sum(weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation data with bounding boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRANS  =  transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],),  # Normalize using precomputed mean and std\n",
    "        transforms.Resize((224, 224),antialias=True),\n",
    "    ])\n",
    "only_bounding_box =  test_df[test_df.target==1]\n",
    "only_bounding_box = only_bounding_box.sample(1000,replace=False,random_state=42)\n",
    "only_bounding_box\n",
    "data_set_train = lung_data(train_df, transform=TRANS)\n",
    "data_set_test = lung_data(only_bounding_box, transform=TRANS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class classifier_model(pl.LightningModule):\n",
    "    def __init__(self, model_string = \"resnet50\",):\n",
    "        super().__init__()\n",
    "        self.model = create_model(model_string, pretrained=True, num_classes=2,in_chans= 3)\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Prodigy(self.parameters(), lr=1, weight_decay=1e-4, )\n",
    "        return optimizer\n",
    "model = classifier_model(\"resnet50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH = 32\n",
    "NUM_WORKERS = multiprocessing.cpu_count() - 2\n",
    "EPOCHS = 10\n",
    "MIXED_PRECISION = False\n",
    "DETERMINISTIC = False\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_set_model_train, batch_size=BATCH, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = torch.utils.data.DataLoader(data_set_model_test, batch_size=BATCH, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS,\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "        precision=16 if MIXED_PRECISION else 32,\n",
    "        default_root_dir=\"classifier_pneunomia_resnet50_logs\",\n",
    "        accumulate_grad_batches=int(32/BATCH,),\n",
    "        deterministic=DETERMINISTIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, test_loader)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "accs = []\n",
    "for batch in test_loader:\n",
    "    x, y, _ = batch\n",
    "    logits = (model(x.cuda())).detach().cpu()\n",
    "    acc = (logits.argmax(1) == y.argmax(1)).float().mean()\n",
    "    accs.append(acc.item())\n",
    "model.cpu()\n",
    "print(\"Accuracy: \", sum(accs) / len(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 32\n",
    "NUM_WORKERS = multiprocessing.cpu_count() - 2\n",
    "EPOCHS = 5\n",
    "MIXED_PRECISION = False\n",
    "DETERMINISTIC = False\n",
    "CONTRASTIVE = False\n",
    "NOISE_MASK = False\n",
    "INVERSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constrastive False\n",
      " The encoder channels are (1024, 512, 256, 64, 3)\n",
      " The decoder channels are (256, 128, 64, 32, 16)\n",
      " The buttom layer is 2048\n",
      " Using image space is True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = classifier_model(\"resnet50\").load_from_checkpoint(\"classifier_pneunomia_resnet50_logs/lightning_logs/version_1/checkpoints/epoch=9-step=6680.ckpt\",strict=False)\n",
    "extractor =  resnet50_img_extractor(model.model)\n",
    "masking_model = resnet50_trained_extractor(extractor, EPOCHS, batch_size=BATCH, lr = 1, \n",
    "                                           center = False, partition = 1, \n",
    "                                           noise_mask = NOISE_MASK, constrastive = CONTRASTIVE, inverse=INVERSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_set_train, batch_size=BATCH, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_set_test, batch_size=BATCH, shuffle=False)\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS,\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\", \n",
    "        precision=16 if MIXED_PRECISION else 32,\n",
    "        default_root_dir=\"masking_supervised_pneumonia_logs\",\n",
    "        accumulate_grad_batches=int(128/BATCH,),\n",
    "        deterministic=DETERMINISTIC\n",
    ")\n",
    "\n",
    "trainer.fit(masking_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masking_model.eval()\n",
    "masking_model = masking_model.to(\"cuda\")\n",
    "nem_path = \"result/supervised/pneunomia/nem_inv/\"\n",
    "os.makedirs(nem_path,exist_ok=True)\n",
    "execution_times = []\n",
    "for (img, y, name) in data_set_test:\n",
    "    name = name.split(\"/\")[-1]\n",
    "    img = img.unsqueeze(0).to(\"cuda\")\n",
    "    start_time = time.time()\n",
    "    attr, _  = masking_model(img)\n",
    "    execution_times.append(time.time()-start_time)\n",
    "    x = img.squeeze().permute(1,2,0).cpu().detach().numpy()\n",
    "    x = ((x - x.min()) / (x.max() - x.min()))*255\n",
    "    attr = attr.cpu().squeeze().detach().numpy()\n",
    "    attr = (((attr - attr.min()) / (attr.max() - attr.min()))*255).astype(np.uint8)\n",
    "    if INVERSE:\n",
    "        attr = 255 - attr\n",
    "\n",
    "\n",
    "\n",
    "    Image.fromarray(attr).save(f\"{nem_path}{name}\")\n",
    "\n",
    "print(\"Average execution time: \", np.array(execution_times).sum()/len(execution_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = GradCAMPlusPlus(model, [model.model.layer4[-1]])   \n",
    "path = \"result/supervised/pneunomia/gradcam/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "execution_times = []\n",
    "for (img,target, name) in data_set_test:\n",
    "    name = name.split(\"/\")[-1]\n",
    "    start_time = time.time()\n",
    "    attr = method(input_tensor=img.unsqueeze(0).cuda(), targets=[ClassifierOutputTarget(target.argmax())]).squeeze()\n",
    "    execution_times.append(time.time()-start_time)\n",
    "    x = img.permute(1,2,0).cpu().detach().numpy()\n",
    "    x = (((x - x.min()) / (x.max() - x.min()))*255).astype(np.uint8)\n",
    "    \n",
    "    attr = (((attr - attr.min()) / (attr.max() - attr.min()))*255).astype(np.uint8)\n",
    "    Image.fromarray(attr).save(f\"{path}{name}\")\n",
    "print(\"Average execution time: \", np.array(execution_times).sum()/len(execution_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientShap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "method = GradientShap(model)\n",
    "baseline = torch.zeros((1, 3, 224, 224)).cuda()\n",
    "path = \"result/supervised/pneunomia/grad_shap/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "execution_times = []\n",
    "for (img,target, name) in data_set_test:\n",
    "    name = name.split(\"/\")[-1]\n",
    "    start_time = time.time()\n",
    "    attr = method.attribute(img.unsqueeze(0).cuda(),baselines=baseline,target= torch.tensor(target.argmax())).squeeze()\n",
    "    execution_times.append(time.time()-start_time)\n",
    "    x = img.permute(1,2,0).cpu().detach().numpy()\n",
    "    x = (((x - x.min()) / (x.max() - x.min()))*255).astype(np.uint8)\n",
    "    attr = torch.abs(attr).sum(0).cpu().numpy()\n",
    "    attr = (((attr - attr.min()) / (attr.max() - attr.min()))*255).astype(np.uint8)\n",
    "    Image.fromarray(attr).save(f\"{path}{name}\")\n",
    "print(\"Average execution time: \", np.array(execution_times).sum()/len(execution_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average execution time:  0.04876405501365662\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "method = IntegratedGradients(model)\n",
    "baseline = torch.zeros((1, 3, 224, 224)).cuda()\n",
    "path = \"result/supervised/pneunomia/integrated_gradients/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "execution_times = []\n",
    "for (img,target, name) in data_set_test:\n",
    "    name = name.split(\"/\")[-1]\n",
    "    start_time = time.time()\n",
    "    attr = method.attribute(img.unsqueeze(0).cuda(),baselines=baseline,target= torch.tensor(target.argmax())).squeeze()\n",
    "    execution_times.append(time.time()-start_time)\n",
    "    x = img.permute(1,2,0).cpu().detach().numpy()\n",
    "    x = (((x - x.min()) / (x.max() - x.min()))*255).astype(np.uint8)\n",
    "    attr = torch.abs(attr).sum(0).cpu().numpy()\n",
    "    attr = (((attr - attr.min()) / (attr.max() - attr.min()))*255).astype(np.uint8)\n",
    "    Image.fromarray(attr).save(f\"{path}{name}\")\n",
    "print(\"Average execution time: \", np.array(execution_times).sum()/len(execution_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth Pixel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")   \n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "class SmoothMask:\n",
    "    def __init__(self, area, model):\n",
    "        self.area = area \n",
    "        self.model = model\n",
    "    def __call__(self, x, pred):\n",
    "        mask, _ = extremal_perturbation(\n",
    "            self.model, x, pred,\n",
    "            reward_func=contrastive_reward,\n",
    "            debug=False,\n",
    "            areas=[self.area]\n",
    "        )\n",
    "        mask \n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average execution time:  3.66284157204628\n"
     ]
    }
   ],
   "source": [
    "method = SmoothMask(model =model, area=0.05)\n",
    "path = \"result/supervised/pneunomia/smooth_mask/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "execution_times = []\n",
    "for (img,target, name) in data_set_test:\n",
    "    name = name.split(\"/\")[-1]\n",
    "    start_time = time.time()\n",
    "    attr = method(img.unsqueeze(0).cuda(), 1)\n",
    "    execution_times.append(time.time()-start_time)\n",
    "\n",
    "    x = img.permute(1,2,0).cpu().detach().numpy()\n",
    "    x = (((x - x.min()) / (x.max() - x.min()))*255).astype(np.uint8)\n",
    "    attr = attr.squeeze().cpu().detach().numpy()\n",
    "    attr = (((attr - attr.min()) / (attr.max() - attr.min()))*255).astype(np.uint8)\n",
    "    Image.fromarray(attr).save(f\"{path}{name}\")\n",
    "print(\"Average execution time: \", np.array(execution_times).sum()/len(execution_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bounding_box(x,y,w,h, size=(224,224)):\n",
    "    \"generate a boundingbox mask using numpy and the input coordinates\"\n",
    "    mask = np.zeros(size)\n",
    "    mask[y:y+h, x:x+w] = 1\n",
    "    return mask.astype(np.uint8)\n",
    "mask_path = \"result/masks/pneunomia/\"\n",
    "os.makedirs(mask_path, exist_ok=True)\n",
    "for sample in only_bounding_box.iterrows():\n",
    "   mask =  gen_bounding_box(sample[1][\"x\"],sample[1][\"y\"],sample[1][\"width\"],sample[1][\"height\"])\n",
    "   Image.fromarray(mask).save(f\"{mask_path}{sample[1]['img_path'].split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(metrics, metric_names,data):\n",
    "    res_path = \"result/supervised/pneunomia/\"\n",
    "    mask_path = \"result/masks/pneunomia/\"\n",
    "    resnet_50_smoothmask_path = f\"{res_path}smooth_mask/\"\n",
    "    resnet_50_gradcam_path = f\"{res_path}gradcam/\"\n",
    "    resnet_50_gradshape_path = f\"{res_path}grad_shap/\"\n",
    "    resnet_50_integrated_gradients_path = f\"{res_path}integrated_gradients/\"\n",
    "    resnet_50_nem_path = f\"{res_path}nem_inv/\"\n",
    "\n",
    "    for metric_func,metric_name in zip(metrics,metric_names):    \n",
    "        resnet_50_smoothmask_res = metric_func(mask_path=mask_path, explanation_path=resnet_50_smoothmask_path, samples=data)\n",
    "        resnet_50_gradcam_res = metric_func(mask_path=mask_path, explanation_path=resnet_50_gradcam_path, samples=data)\n",
    "        resnet_50_gradshape_res = metric_func(mask_path=mask_path, explanation_path=resnet_50_gradshape_path, samples=data)\n",
    "        resnet_50_integrated_gradients_res = metric_func(mask_path=mask_path, explanation_path=resnet_50_integrated_gradients_path, samples=data)\n",
    "        resnet_50_nem_res = metric_func(mask_path=mask_path, explanation_path=resnet_50_nem_path, samples=data)\n",
    "\n",
    "\n",
    "        print(f\"\"\"\n",
    "        {metric_name}:\n",
    "        resnet_50_smoothmask:     {resnet_50_smoothmask_res}\n",
    "        resnet_50_gradcam:        {resnet_50_gradcam_res}\n",
    "        resnet_50_gradshape:      {resnet_50_gradshape_res}\n",
    "        resnet_50_integrated_gradients: {resnet_50_integrated_gradients_res}\n",
    "        resnet_50_nem:            {resnet_50_nem_res}\n",
    "        \"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_rank( mask_path, explanation_path, samples):\n",
    "    rank_accuracy = 0\n",
    "    samps = 0\n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        s = (np.array(Image.open(mask_path + img_name)) > 0).astype(np.uint8)\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # Prepare shapes.\n",
    "        a = a.flatten()\n",
    "        s = np.where(s.flatten().astype(bool))[0]\n",
    "        # Size of the ground truth mask.\n",
    "        k = len(s)\n",
    "        # Sort in descending order.\n",
    "        a_sorted = np.argsort(a)[-int(k) :]\n",
    "        # Calculate hits.\n",
    "        hits = len(np.intersect1d(s, a_sorted))\n",
    "        if hits != 0:\n",
    "            rank_accuracy += hits / float(k)\n",
    "        else:\n",
    "            rank_accuracy += 0.0\n",
    "        samps +=1 \n",
    "\n",
    "\n",
    "\n",
    "    return rank_accuracy/ samps\n",
    "\n",
    "def relevancy_mass(mask_path, explanation_path, samples):\n",
    "    mass_accuracy_total = 0\n",
    "    samps = 0\n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        s = (np.array(Image.open(mask_path + img_name)) > 0).astype(np.uint8)\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # \n",
    "        a = a.flatten()\n",
    "        s = s.flatten().astype(bool)\n",
    "        # Compute inside/outside ratio.\n",
    "        r_within = np.sum(a[s])\n",
    "        r_total = np.sum(a)\n",
    "        # Calculate mass accuracy.\n",
    "        mass_accuracy = r_within / r_total\n",
    "        mass_accuracy_total += mass_accuracy\n",
    "        samps +=1\n",
    "\n",
    "    return mass_accuracy_total/ samps\n",
    "     \n",
    "\n",
    "run_exp([\n",
    "    \n",
    "     relevance_rank, relevancy_mass],\n",
    "        [\n",
    "     \"Relevance Rank\", \"Relevancy Mass\"],\n",
    "    only_bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complexity( mask_path, explanation_path, samples):\n",
    "    complexity = 0\n",
    "    \n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # Prepare shapes.\n",
    "        newshape = np.prod(a.shape)\n",
    "        a = np.array(np.reshape(a, newshape), dtype=np.float64) / np.sum(np.abs(a))\n",
    "        complexity += scipy.stats.entropy(pk=a)   \n",
    "\n",
    "\n",
    "    return complexity/ len(samples)\n",
    "\n",
    "\n",
    "def sparseness( mask_path, explanation_path, samples):\n",
    "    complexity = 0\n",
    "    \n",
    "    for i, sample in samples.iterrows():\n",
    "        img_name = sample[\"img_path\"].split(\"/\")[-1]\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        # Prepare shapes.\n",
    "        newshape = np.prod(a.shape)\n",
    "        a = np.array(np.reshape(a, newshape), dtype=np.float64)\n",
    "        a += 0.0000001\n",
    "        a = np.sort(a)\n",
    "        complexity += (np.sum((2 * np.arange(1, a.shape[0] + 1) - a.shape[0] - 1) * a)) / (\n",
    "            a.shape[0] * np.sum(a)\n",
    "        )\n",
    "\n",
    "    return complexity/ len(samples)\n",
    "\n",
    "\n",
    "run_exp([\n",
    "    complexity, \n",
    "    sparseness\n",
    "    ],\n",
    "        [\n",
    "    \"Complexity\", \n",
    "    \"Sparseness\"\n",
    "    ],\n",
    "    only_bounding_box)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faithfullness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faithfullness(mask_path, explanation_path, samples):\n",
    "    metric = FaithfulnessEstimate(features_in_step=224 * 4)\n",
    "    values = []\n",
    "    i = 0\n",
    "    for X,Y,img_name in samples:\n",
    "        i += 1\n",
    "        img_name = img_name.split(\"/\")[-1]\n",
    "        a =  np.array(Image.open(explanation_path +  img_name))/255\n",
    "        Y = Y.argmax()\n",
    "        values +=   metric(model=model.cuda().eval(),\n",
    "                            x_batch=X.unsqueeze(0).numpy(), y_batch=np.expand_dims(Y.astype(np.uint8), axis=0),\n",
    "                              a_batch=np.expand_dims(a, axis=0),device=\"cuda\")\n",
    "    return np.nanmean(values)\n",
    "\n",
    "    \n",
    "run_exp([faithfullness],\n",
    "        [\"Faithfullness\"],\n",
    "    data_set_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MICCAI_COMPARE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
